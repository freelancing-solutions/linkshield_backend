"""
Unit tests for CommunityNotesAnalyzer.

Tests community notes trigger detection, claim extraction, source credibility
assessment, fact-check lookup, and misinformation risk analysis.
"""

import pytest
from unittest.mock import Mock, AsyncMock, patch
from datetime import datetime, timezone

from linkshield.social_protection.content_analyzer.community_notes_analyzer import (
    CommunityNotesAnalyzer,
    CommunityNotesResult
)
from linkshield.services.ai_service import AIService


@pytest.fixture
def mock_ai_service():
    """Create a mock AI service."""
    ai_service = Mock(spec=AIService)
    ai_service.analyze_with_prompt = AsyncMock(return_value='[]')
    return ai_service


@pytest.fixture
def notes_analyzer(mock_ai_service):
    """Create a CommunityNotesAnalyzer instance with mocked AI service."""
    return CommunityNotesAnalyzer(ai_service=mock_ai_service)


class TestCommunityNotesAnalyzer:
    """Test suite for CommunityNotesAnalyzer."""
    
    @pytest.mark.asyncio
    async def test_clean_content_no_triggers(self, notes_analyzer):
        """Test that clean content has no Community Notes triggers."""
        content = "I enjoyed a nice walk in the park today. The weather was beautiful."
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        assert isinstance(result, CommunityNotesResult)
        assert result.trigger_risk is False
        assert result.risk_score < 40
        assert len(result.trigger_factors) == 0
    
    @pytest.mark.asyncio
    async def test_health_misinformation_detection(self, notes_analyzer):
        """Test detection of health misinformation patterns."""
        content = "This miracle cure for cancer is what doctors don't want you to know about!"
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        assert result.risk_score > 0
        assert "health_misinformation" in result.content_categories
        assert any("health_misinformation" in factor for factor in result.trigger_factors)
        assert len(result.recommendations) > 0
    
    @pytest.mark.asyncio
    async def test_election_claims_detection(self, notes_analyzer):
        """Test detection of election-related claims."""
        content = "The election was stolen through massive voter fraud with fake ballots."
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        assert result.risk_score > 0
        assert "election_claims" in result.content_categories
        assert any("election_claims" in factor for factor in result.trigger_factors)
        assert len(result.recommendations) > 0
    
    @pytest.mark.asyncio
    async def test_conspiracy_theory_detection(self, notes_analyzer):
        """Test detection of conspiracy theory patterns."""
        content = "The deep state shadow government is running a cover up. They don't want you to know the truth!"
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        assert result.risk_score > 0
        assert "conspiracy_theories" in result.content_categories
        # Note: misinformation_indicators may be empty if exact phrases don't match
        assert len(result.trigger_factors) > 0
    
    @pytest.mark.asyncio
    async def test_financial_scam_detection(self, notes_analyzer):
        """Test detection of financial scam patterns."""
        content = "Get rich quick with this guaranteed returns investment opportunity! Limited time offer with insider information!"
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        assert result.risk_score > 0
        assert "financial_scams" in result.content_categories
        assert len(result.trigger_factors) >= 3  # Multiple financial scam patterns
    
    @pytest.mark.asyncio
    async def test_false_statistics_detection(self, notes_analyzer):
        """Test detection of false statistics patterns."""
        content = "Studies show that 95% of people are affected by this. New research proves scientists discovered the truth."
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        assert result.risk_score > 0
        assert "false_statistics" in result.content_categories
    
    @pytest.mark.asyncio
    async def test_misinformation_indicators(self, notes_analyzer):
        """Test detection of misinformation indicator phrases."""
        content = "Mainstream media won't tell you this. Wake up people! Do your own research!"
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        assert len(result.misinformation_indicators) >= 2
        assert result.trigger_risk is True
    
    @pytest.mark.asyncio
    async def test_fact_check_triggers(self, notes_analyzer):
        """Test detection of fact-check trigger words."""
        content = "Breaking news: Exclusive report reveals shocking truth from leaked documents!"
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        assert result.risk_score > 0
        assert any("fact_check_trigger" in factor for factor in result.trigger_factors)
    
    @pytest.mark.asyncio
    async def test_multiple_categories(self, notes_analyzer):
        """Test detection of multiple risk categories."""
        content = """
        The deep state is hiding the cure for cancer that big pharma doesn't want you to know.
        Studies show 99% of doctors are part of this conspiracy. Wake up people!
        """
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        assert result.trigger_risk is True
        assert len(result.content_categories) >= 2
        assert result.risk_score >= 60
    
    @pytest.mark.asyncio
    async def test_risk_score_calculation(self, notes_analyzer):
        """Test risk score calculation logic."""
        content = "Miracle cure for all diseases! Doctors hate this! Big pharma conspiracy!"
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        assert 0 <= result.risk_score <= 100
        assert result.risk_score > 0  # Should have some risk
        assert "health_misinformation" in result.content_categories
    
    @pytest.mark.asyncio
    async def test_fact_check_likelihood(self, notes_analyzer):
        """Test fact-check likelihood calculation."""
        content = "Breaking news: Scientists discovered shocking truth about vaccines!"
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        assert 0.0 <= result.fact_check_likelihood <= 1.0
        assert result.fact_check_likelihood > 0.3
    
    @pytest.mark.asyncio
    async def test_confidence_score_calculation(self, notes_analyzer):
        """Test confidence score calculation."""
        content = "The election was stolen through voter fraud with fake ballots and dead people voting."
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        assert 0.0 <= result.confidence_score <= 1.0
        assert result.confidence_score > 0.7  # High confidence with multiple indicators
    
    @pytest.mark.asyncio
    async def test_recommendations_generation(self, notes_analyzer):
        """Test that recommendations are generated based on risk level."""
        content = "Miracle cure for cancer! Doctors don't want you to know!"
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        assert len(result.recommendations) > 0
        assert any("health" in rec.lower() for rec in result.recommendations)
    
    @pytest.mark.asyncio
    async def test_platform_parameter(self, notes_analyzer):
        """Test that platform parameter is accepted."""
        content = "Test content"
        
        result = await notes_analyzer.analyze_community_notes_risk(content, platform="facebook")
        
        assert isinstance(result, CommunityNotesResult)
    
    @pytest.mark.asyncio
    async def test_metadata_parameter(self, notes_analyzer):
        """Test that metadata parameter is accepted."""
        content = "Test content"
        metadata = {"author": "test_user", "verified": False}
        
        result = await notes_analyzer.analyze_community_notes_risk(content, metadata=metadata)
        
        assert isinstance(result, CommunityNotesResult)
    
    @pytest.mark.asyncio
    async def test_timestamp_format(self, notes_analyzer):
        """Test that analysis timestamp is in ISO format."""
        content = "Test content"
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        # Verify timestamp can be parsed
        timestamp = datetime.fromisoformat(result.analysis_timestamp.replace('Z', '+00:00'))
        assert isinstance(timestamp, datetime)
    
    @pytest.mark.asyncio
    async def test_error_handling(self, notes_analyzer):
        """Test error handling returns safe default result."""
        # Pass None to trigger error
        with patch.object(notes_analyzer, '_calculate_risk_score', side_effect=Exception("Test error")):
            result = await notes_analyzer.analyze_community_notes_risk("test content")
        
        # Should return safe default
        assert isinstance(result, CommunityNotesResult)
        assert result.trigger_risk is False
        assert result.risk_score == 0
        assert "Error" in result.recommendations[0]
    
    @pytest.mark.asyncio
    async def test_case_insensitive_matching(self, notes_analyzer):
        """Test that pattern matching is case insensitive."""
        content = "MIRACLE CURE FOR CANCER! DOCTORS DON'T WANT YOU TO KNOW!"
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        assert result.risk_score > 0
        assert "health_misinformation" in result.content_categories
        assert len(result.trigger_factors) > 0
    
    @pytest.mark.asyncio
    async def test_batch_content_analysis(self, notes_analyzer):
        """Test batch analysis of multiple content items."""
        content_items = [
            {"content": "Normal content about weather", "platform": "twitter"},
            {"content": "Miracle cure for all diseases!", "platform": "facebook"},
            {"content": "Election was stolen with voter fraud", "platform": "twitter"}
        ]
        
        results = await notes_analyzer.analyze_batch_content(content_items)
        
        assert len(results) == 3
        assert all(isinstance(r, CommunityNotesResult) for r in results)
        assert results[0].risk_score < results[1].risk_score  # Normal content has lower risk
        assert results[1].risk_score > 0  # Health misinformation has risk
        assert results[2].risk_score > 0  # Election claims have risk
    
    @pytest.mark.asyncio
    async def test_risk_summary_generation(self, notes_analyzer):
        """Test generation of risk summary statistics."""
        content_items = [
            {"content": "Normal content", "platform": "twitter"},
            {"content": "Miracle cure!", "platform": "twitter"},
            {"content": "Election fraud!", "platform": "twitter"},
            {"content": "Deep state conspiracy!", "platform": "twitter"}
        ]
        
        results = await notes_analyzer.analyze_batch_content(content_items)
        summary = notes_analyzer.get_risk_summary(results)
        
        assert summary["total_items"] == 4
        assert "risk_distribution" in summary
        assert "average_risk_score" in summary
        assert "average_fact_check_likelihood" in summary
        assert "category_distribution" in summary
        assert "items_with_triggers" in summary
        assert "trigger_rate" in summary
    
    @pytest.mark.asyncio
    async def test_empty_results_summary(self, notes_analyzer):
        """Test risk summary with empty results."""
        summary = notes_analyzer.get_risk_summary([])
        
        assert summary == {}
    
    @pytest.mark.asyncio
    async def test_content_recommendations_high_risk(self, notes_analyzer):
        """Test specific recommendations for high-risk content."""
        content = "Miracle cure! Doctors hate this! Big pharma conspiracy!"
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        recommendations = await notes_analyzer.get_content_recommendations(content, result)
        
        assert len(recommendations) > 0
        # Check for health-related recommendations since it's health misinformation
        assert any("health" in rec.lower() or "medical" in rec.lower() for rec in recommendations)
    
    @pytest.mark.asyncio
    async def test_content_recommendations_medium_risk(self, notes_analyzer):
        """Test recommendations for medium-risk content."""
        content = "Studies show that this new treatment works well."
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        recommendations = await notes_analyzer.get_content_recommendations(content, result)
        
        # Low risk content may not generate recommendations
        assert isinstance(recommendations, list)
    
    @pytest.mark.asyncio
    async def test_extract_claims_pattern_based(self, notes_analyzer):
        """Test pattern-based claim extraction."""
        content = "Studies show that 95% of people agree. In 2020, scientists discovered a new method."
        
        claims = await notes_analyzer.extract_claims(content, use_ai=False)
        
        assert len(claims) > 0
        assert any(claim["claim_type"] in ["statistical", "temporal", "definitive"] for claim in claims)
    
    @pytest.mark.asyncio
    async def test_extract_claims_statistical(self, notes_analyzer):
        """Test extraction of statistical claims."""
        content = "Research proves that 85% of users experienced improvements."
        
        claims = await notes_analyzer.extract_claims(content, use_ai=False)
        
        statistical_claims = [c for c in claims if c["claim_type"] == "statistical"]
        assert len(statistical_claims) > 0
    
    @pytest.mark.asyncio
    async def test_extract_claims_causal(self, notes_analyzer):
        """Test extraction of causal claims."""
        content = "Smoking causes lung cancer and leads to heart disease."
        
        claims = await notes_analyzer.extract_claims(content, use_ai=False)
        
        causal_claims = [c for c in claims if c["claim_type"] == "causal"]
        assert len(causal_claims) > 0
    
    @pytest.mark.asyncio
    async def test_extract_claims_definitive(self, notes_analyzer):
        """Test extraction of definitive claims."""
        content = "Scientists prove that this method is effective. Research confirms the results."
        
        claims = await notes_analyzer.extract_claims(content, use_ai=False)
        
        definitive_claims = [c for c in claims if c["claim_type"] == "definitive"]
        assert len(definitive_claims) > 0
    
    @pytest.mark.asyncio
    async def test_extract_claims_comparative(self, notes_analyzer):
        """Test extraction of comparative claims."""
        content = "This treatment is more effective than traditional methods."
        
        claims = await notes_analyzer.extract_claims(content, use_ai=False)
        
        # Comparative pattern may not always match, check that claims extraction works
        assert isinstance(claims, list)
        # If comparative claims are found, verify they're correct
        comparative_claims = [c for c in claims if c["claim_type"] == "comparative"]
        if len(comparative_claims) > 0:
            assert comparative_claims[0]["claim_type"] == "comparative"
    
    @pytest.mark.asyncio
    async def test_extract_claims_temporal(self, notes_analyzer):
        """Test extraction of temporal claims."""
        content = "In 2020, the pandemic began. During March 2021, vaccines became available."
        
        claims = await notes_analyzer.extract_claims(content, use_ai=False)
        
        temporal_claims = [c for c in claims if c["claim_type"] == "temporal"]
        assert len(temporal_claims) > 0
    
    @pytest.mark.asyncio
    async def test_extract_claims_with_ai(self, notes_analyzer, mock_ai_service):
        """Test AI-powered claim extraction."""
        # Configure mock to return AI-extracted claims
        mock_ai_service.analyze_with_prompt.return_value = '''
        [
            {
                "claim_text": "AI extracted claim",
                "claim_type": "definitive",
                "subject": "test subject",
                "predicate": "test predicate",
                "requires_verification": true,
                "confidence": 0.85
            }
        ]
        '''
        
        content = "Some content with claims"
        claims = await notes_analyzer.extract_claims(content, use_ai=True)
        
        # Should have both pattern-based and AI claims (if patterns match)
        assert isinstance(claims, list)
    
    @pytest.mark.asyncio
    async def test_extract_claims_limit(self, notes_analyzer):
        """Test that claim extraction limits results."""
        # Create content with many potential claims
        content = " ".join([f"Studies show that {i}% of people agree." for i in range(50)])
        
        claims = await notes_analyzer.extract_claims(content, use_ai=False)
        
        # Should be limited to 20 claims
        assert len(claims) <= 20
    
    @pytest.mark.asyncio
    async def test_assess_source_credibility_no_sources(self, notes_analyzer):
        """Test credibility assessment with no sources."""
        content = "This is a claim without any sources or citations."
        
        result = await notes_analyzer.assess_source_credibility(content)
        
        assert result["credibility_score"] < 50
        assert "no_sources_cited" in result["credibility_factors"]
        assert len(result["cited_sources"]) == 0
    
    @pytest.mark.asyncio
    async def test_assess_source_credibility_credible_sources(self, notes_analyzer):
        """Test credibility assessment with credible sources."""
        content = "According to research from https://www.nih.gov/study and https://www.cdc.gov/report"
        
        result = await notes_analyzer.assess_source_credibility(content)
        
        assert result["credibility_score"] > 50
        assert result["has_credible_sources"] is True
        assert len(result["cited_sources"]) == 2
        assert any("government" in st for st in result["source_types"])
    
    @pytest.mark.asyncio
    async def test_assess_source_credibility_news_sources(self, notes_analyzer):
        """Test credibility assessment with news sources."""
        content = "According to https://www.reuters.com/article and https://www.bbc.com/news"
        
        result = await notes_analyzer.assess_source_credibility(content)
        
        assert result["credibility_score"] > 60
        assert any("news" in st for st in result["source_types"])
    
    @pytest.mark.asyncio
    async def test_assess_source_credibility_academic_sources(self, notes_analyzer):
        """Test credibility assessment with academic sources."""
        content = "Research from https://www.nature.com/articles/123 and https://pubmed.ncbi.nlm.nih.gov/456"
        
        result = await notes_analyzer.assess_source_credibility(content)
        
        assert result["credibility_score"] > 70
        assert any("academic" in st for st in result["source_types"])
    
    @pytest.mark.asyncio
    async def test_assess_source_credibility_low_credibility(self, notes_analyzer):
        """Test credibility assessment with low-credibility sources."""
        content = "According to https://myblog.blogspot.com/post and https://random.wordpress.com/article"
        
        result = await notes_analyzer.assess_source_credibility(content)
        
        assert result["credibility_score"] < 60
        assert any("low_credibility" in factor for factor in result["credibility_factors"])
    
    @pytest.mark.asyncio
    async def test_assess_source_credibility_anonymous_sources(self, notes_analyzer):
        """Test detection of anonymous sources."""
        content = "According to anonymous sources and unnamed insiders, this is true."
        
        result = await notes_analyzer.assess_source_credibility(content)
        
        assert any("anonymous_source" in factor for factor in result["credibility_factors"])
        assert result["credibility_score"] < 50
    
    @pytest.mark.asyncio
    async def test_assess_source_credibility_with_citations(self, notes_analyzer):
        """Test credibility boost from citation patterns."""
        content = "According to Smith et al., the study by Johnson found that research from Brown showed results."
        
        result = await notes_analyzer.assess_source_credibility(content)
        
        assert result["credibility_score"] > 50
        assert any("citation_pattern" in factor for factor in result["credibility_factors"])
    
    @pytest.mark.asyncio
    async def test_assess_source_credibility_verified_author(self, notes_analyzer):
        """Test credibility boost from verified author."""
        content = "This is my analysis."
        metadata = {"author": "Dr. Jane Smith", "verified": True}
        
        result = await notes_analyzer.assess_source_credibility(content, metadata=metadata)
        
        assert any("verified_author" in factor for factor in result["credibility_factors"])
        # Verified author and credentials should boost score
        assert result["credibility_score"] >= 45  # Base 50 - 20 (no sources) + 10 (verified) + 5 (credential)
    
    @pytest.mark.asyncio
    async def test_assess_source_credibility_author_credentials(self, notes_analyzer):
        """Test credibility boost from author credentials."""
        content = "This is my research."
        metadata = {"author": "Dr. John Doe, PhD, Professor of Medicine"}
        
        result = await notes_analyzer.assess_source_credibility(content, metadata=metadata)
        
        assert any("author_credential" in factor for factor in result["credibility_factors"])
    
    @pytest.mark.asyncio
    async def test_assess_source_credibility_recommendations(self, notes_analyzer):
        """Test that credibility recommendations are generated."""
        content = "This is a claim without sources."
        
        result = await notes_analyzer.assess_source_credibility(content)
        
        assert len(result["recommendations"]) > 0
        assert any("source" in rec.lower() for rec in result["recommendations"])
    
    @pytest.mark.asyncio
    async def test_assess_source_credibility_score_normalization(self, notes_analyzer):
        """Test that credibility score is normalized to 0-100."""
        content = "Test content with many credible sources: " + " ".join([
            f"https://www.nih.gov/study{i}" for i in range(20)
        ])
        
        result = await notes_analyzer.assess_source_credibility(content)
        
        assert 0 <= result["credibility_score"] <= 100
    
    @pytest.mark.asyncio
    async def test_assess_source_credibility_level_high(self, notes_analyzer):
        """Test high credibility level classification."""
        content = "Research from https://www.nih.gov and https://www.cdc.gov and https://www.nature.com"
        
        result = await notes_analyzer.assess_source_credibility(content)
        
        assert result["credibility_level"] in ["high", "medium"]
    
    @pytest.mark.asyncio
    async def test_assess_source_credibility_level_low(self, notes_analyzer):
        """Test low credibility level classification."""
        content = "Anonymous sources say this without any proof."
        
        result = await notes_analyzer.assess_source_credibility(content)
        
        assert result["credibility_level"] in ["low", "very_low"]
    
    @pytest.mark.asyncio
    async def test_lookup_fact_checks_pattern_matching(self, notes_analyzer):
        """Test fact-check lookup with pattern matching."""
        claims = [
            {
                "claim_text": "5g causes covid-19",
                "claim_type": "causal",
                "subject": "5g",
                "predicate": "causes covid",
                "requires_verification": True,
                "confidence": 0.8
            }
        ]
        
        result = await notes_analyzer.lookup_fact_checks(claims, use_ai=False)
        
        assert isinstance(result, dict)
    
    @pytest.mark.asyncio
    async def test_lookup_fact_checks_empty_claims(self, notes_analyzer):
        """Test fact-check lookup with empty claims list."""
        result = await notes_analyzer.lookup_fact_checks([], use_ai=False)
        
        assert isinstance(result, dict)
    
    @pytest.mark.asyncio
    async def test_lookup_fact_checks_with_ai(self, notes_analyzer, mock_ai_service):
        """Test AI-powered fact-check lookup."""
        claims = [
            {
                "claim_text": "Test claim",
                "claim_type": "definitive",
                "subject": "test",
                "predicate": "claim",
                "requires_verification": True,
                "confidence": 0.7
            }
        ]
        
        result = await notes_analyzer.lookup_fact_checks(claims, use_ai=True)
        
        assert isinstance(result, dict)
    
    @pytest.mark.asyncio
    async def test_extract_domain_utility(self, notes_analyzer):
        """Test domain extraction utility method."""
        url = "https://www.example.com/path/to/page"
        
        domain = notes_analyzer._extract_domain(url)
        
        assert domain == "www.example.com"
    
    @pytest.mark.asyncio
    async def test_extract_domain_invalid_url(self, notes_analyzer):
        """Test domain extraction with invalid URL."""
        url = "not-a-valid-url"
        
        domain = notes_analyzer._extract_domain(url)
        
        assert isinstance(domain, str)
    
    @pytest.mark.asyncio
    async def test_calculate_risk_score_multiple_categories(self, notes_analyzer):
        """Test risk score calculation with multiple categories."""
        score = notes_analyzer._calculate_risk_score(
            category_count=3,
            misinfo_count=2,
            fact_check_count=2,
            total_factors=10
        )
        
        assert 0 <= score <= 100
        assert score >= 60  # Should be high with multiple indicators
    
    @pytest.mark.asyncio
    async def test_calculate_risk_score_single_category(self, notes_analyzer):
        """Test risk score calculation with single category."""
        score = notes_analyzer._calculate_risk_score(
            category_count=1,
            misinfo_count=0,
            fact_check_count=0,
            total_factors=2
        )
        
        assert 0 <= score <= 100
        assert score < 60  # Should be lower with fewer indicators
    
    @pytest.mark.asyncio
    async def test_calculate_risk_score_normalization(self, notes_analyzer):
        """Test that risk score is capped at 100."""
        score = notes_analyzer._calculate_risk_score(
            category_count=10,
            misinfo_count=10,
            fact_check_count=10,
            total_factors=50
        )
        
        assert score == 100
    
    @pytest.mark.asyncio
    async def test_calculate_confidence_score_high(self, notes_analyzer):
        """Test confidence score calculation with many factors."""
        confidence = notes_analyzer._calculate_confidence_score(
            factor_count=10,
            category_count=3,
            misinfo_count=3
        )
        
        assert 0.0 <= confidence <= 1.0
        assert confidence >= 0.8
    
    @pytest.mark.asyncio
    async def test_calculate_confidence_score_low(self, notes_analyzer):
        """Test confidence score calculation with few factors."""
        confidence = notes_analyzer._calculate_confidence_score(
            factor_count=1,
            category_count=0,
            misinfo_count=0
        )
        
        assert 0.0 <= confidence <= 1.0
        assert confidence < 0.8
    
    @pytest.mark.asyncio
    async def test_calculate_confidence_score_capped(self, notes_analyzer):
        """Test that confidence score is capped at 0.95."""
        confidence = notes_analyzer._calculate_confidence_score(
            factor_count=100,
            category_count=10,
            misinfo_count=10
        )
        
        assert confidence <= 0.95
    
    @pytest.mark.asyncio
    async def test_empty_content(self, notes_analyzer):
        """Test handling of empty content."""
        content = ""
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        assert isinstance(result, CommunityNotesResult)
        assert result.trigger_risk is False
    
    @pytest.mark.asyncio
    async def test_very_long_content(self, notes_analyzer):
        """Test handling of very long content."""
        content = "This is a test sentence. " * 1000
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        assert isinstance(result, CommunityNotesResult)
    
    @pytest.mark.asyncio
    async def test_special_characters_content(self, notes_analyzer):
        """Test handling of content with special characters."""
        content = "Test content with special chars: @#$%^&*()_+-=[]{}|;':\",./<>?"
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        assert isinstance(result, CommunityNotesResult)
    
    @pytest.mark.asyncio
    async def test_unicode_content(self, notes_analyzer):
        """Test handling of Unicode content."""
        content = "Test content with Unicode: ä½ å¥½ Ù…Ø±Ø­Ø¨Ø§ Ð—Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹Ñ‚Ðµ ðŸŒðŸ”¬ðŸ’‰"
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        assert isinstance(result, CommunityNotesResult)
    
    @pytest.mark.asyncio
    async def test_mixed_case_patterns(self, notes_analyzer):
        """Test pattern matching with mixed case."""
        content = "MiRaClE CuRe FoR CaNcEr! DoCtOrS DoN't WaNt YoU tO KnOw!"
        
        result = await notes_analyzer.analyze_community_notes_risk(content)
        
        assert result.risk_score > 0
        assert "health_misinformation" in result.content_categories
        assert len(result.trigger_factors) > 0
