
---
## 1. The Idea in One Sentence  
LinkShield is the **â€œsafety scanner for everything you meet onlineâ€** â€“ one box, one click, and you instantly know if a **website**, **social account**, or **the links they share** is safe, shady, or dangerous.
---

## 2. Who Is It For?  
- **Casual users** â€“ check a link before you click.  
- **Shoppers** â€“ check a store before you pay.  
- **Influencers** â€“ prove your profile and last posts are clean.  
- **Brand managers** â€“ watch your own site & socials 24/7 and get an alert if anything turns bad.

---

## 3. What Can You Do? (Features in Plain Words)  

| Feature | Free | Logged-in (subscribers) |
|---|---|---|
| **Quick Scan** â€“ paste ANY link â†’ green / red card in 2 s | âœ… unlimited | âœ… |
| **Site-DNA card** â€“ tiny â€œwhyâ€ section: age, certs, reviews | âœ… first 5 / day | âœ… unlimited |
| **Deep-Link Audit** â€“ see **all** outbound links of that site and their safety | âœ… 3 scans / month | âœ… 200 / month |
| **Social Safety** â€“ paste `@handle` or TikTok/Instagram/Youtube/LinkedIn URL â†’ get account age, fake-follower check, scam-keywords in bio & last posts | âœ… 5 scans / month | âœ… 200 / month |
| **Community Meter** â€“ small bar â€œ93 % of users flagged this as scamâ€ | âœ… | âœ… |
| **Watch-list (monitor)** â€“ we re-check **your** site or handle every day and email you if it turns bad | âŒ | âœ… |
| **Export CSV / JSON** â€“ download full lists of flagged links | âŒ | âœ… |
| **Bulk API** â€“ send 100 links at once | âŒ | âœ… |

*Everything uses the **same input box** on the home page.  
Subscribers also get a **simple dashboard** to pick â€œScan onceâ€ or â€œMonitorâ€.*

---

## 4. How It Works (Behind the Curtains)  
1. You paste something.  
2. We **guess** what you gave us:  
   - looks like `https://â€¦` â†’ **website scan**  
   - looks like `@username` or `tiktok.com/@xyz` â†’ **social scan**  
3. We fetch public data â†’ run **AI + 40 threat lists + community votes** â†’ build a **card**.  
4. If you are **monitoring**, we store a **hash** of the address (no personal data) and repeat the scan every night.

---

## 5. Detailed Development Plan  
*FastAPI + PostgreSQL + Redis + Celery â€“ same stack you already have.*

### PHASE 0 â€“ Prepare (week 1)  
- [ ] Create GitHub milestone `LS-v1-deep-rep`  
- [ ] Add env variables:  
  `MAX_FREE_DEEP=3`, `MAX_FREE_SOCIAL=5`, `MONITOR_ENABLED=false` (upgraded users)  

### PHASE 1 â€“ Quick Wins (weeks 1-2)  
**Back-end**  
- [ ] Return **confidence %** in `/scan` â†’ `ai_confidence` field  
- [ ] Add **registrar-age-cert** features to Random-Forest â†’ new model `rf_v3.2.joblib`  
- [ ] Store **community votes** (IP-hash + daily salt) â†’ Kafka topic + Postgres table `community_vote`  

**Front-end**  
- [ ] Collapsible **Site-DNA card** (age, certs, rank) â€“ shows after scan  
- [ ] Tiny **community meter** bar under card  

### PHASE 2 â€“ Deep-Link Audit (weeks 2-3)  
**Back-end**  
- [ ] New endpoint `POST /api/v1/scan/deep` â†’ returns `scan_id` (202)  
- [ ] Spider:  
  - max 25 pages, max 100 external links, obey `robots.txt`  
  - deduplicate by second-level domain + path sha256  
- [ ] Celery chord: expand short URLs â†’ batch-call existing classifier â†’ save results  
- [ ] New table `deep_scan` + `deep_link` (foreign key)  
- [ ] Route `/export/deep/{id}?token=JWT` â†’ CSV (premium only)  

**Front-end**  
- [ ] Add **â€œDeep-Link Audit â–¸â€** row in card (free users see first 10 rows, paginated)  

### PHASE 3 â€“ Social Safety (weeks 3-4)  
**Back-end**  
- [ ] Regex router in `/scan` â†’ if pattern = social â†’ redirect to `POST /api/v1/scan/social`  
- [ ] Platform modules: `tiktok.py`, `twitter.py`, `instagram.py` (read-only tokens)  
- [ ] Fetch: account meta + last 50 posts/media â†’ extract **bio link + caption links**  
- [ ] Run **keyword detector** on bio + captions â†’ `keyword_risk_score`  
- [ ] Run **follower spike detector** (Isolation-Forest on timeseries) â†’ `impersonation_score`  
- [ ] Re-use Deep-Link chord for **all extracted links**  

**Front-end**  
- [ ] Show **social card**: verification badge, age, scores, flagged links table  

### PHASE 4 â€“ Monitoring & Dashboard (week 4)  
**Back-end**  
- [ ] New table `watchlist` (user_id, target_hash, type, created_at)  
- [ ] Nightly cron â†’ re-scans entries â†’ if **new** flagged links or verdict change â†’ send email  
- [ ] Simple **Stripe checkout** â†’ on success set `MONITOR_ENABLED=true`  

**Front-end dashboard** (subscribers only)  
- [ ] Tabs: â€œQuick Scanâ€, â€œMy Watch-listâ€, â€œExport Historyâ€  
- [ ] Buttons: â€œAdd to watch-listâ€ appears after any scan  

### PHASE 5 â€“ Harden & Measure (week 5, buffer)  
- [ ] Add **rate-limit**: deep scans count as 5 normal scans  
- [ ] Write **tests** (unit â‰¥ 80 %, Cypress smoke)  
- [ ] **Metrics** dashboard: median latency â‰¤ 1.2 s, community spam â‰¤ 2 %  
- [ ] Update public **docs** (Swagger + entry-level FAQ)  

---

## 6. What We DO NOT Build (Keep It Light)  
- No browsing-history storage  
- No private-profile scraping  
- No credit-score-style consumer reports  
- No closed-source browser extension (stay web-first)

---

## 7. Success Numbers We Want  
- 1 000 deep scans/day within 6 weeks  
- 50 paying monitor users (â‚¬5/month) within 3 months  
- F1 score â‰¥ 98 % on URL classifier after adding registrar features  

---

## 8. Next Click for You  
ğŸ‘ **Approve** â†’ I open all GitHub issues and start code branches.  
ğŸ”„ **Tweak numbers** â†’ tell me and I update the plan.
